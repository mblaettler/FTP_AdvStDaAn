% !TeX spellcheck = en_GB
\section{Part1: Advanced regression modelling}

Depending on the response variable (the value we'd like to model) a different model must be choosen.

\begin{tabular}{|l|l|}
	\hline 
	\textbf{Response} & \textbf{Model} \\ 
	\hline 
	Continuous (with condtant variance) & Multiple linear regression model \\ 
	\hline 
	Zero/one variate & Logistic regression model \\ 
	\hline 
	Counts & Loglinear model \\ 
	\hline 
	Continuous (with constant coefficient of variation) & Gamma regression model \\ 
	\hline 
	Censored survival times & Accelerated Failure Times Models \\
	& Proportional hazard model \\
	\hline 
\end{tabular} 

\subsection{Linear Regression (Recap)}

Form: $y \approx \beta_0 + \beta_1 x_i^{(1)} + ... + \beta_m x_i^{(m)}$\\
With $x_i^{1...m}$ being the \textbf{predictor variables} and $y$ the \textbf{response variable}. If $m=1$ the method is called \textbf{simple regression} otherwise \textbf{multiple regression}. While the \textbf{predictor variables} $x_i^{1...m}$ can be a non-linear combination of variables, the $\beta$s can only be multiplied (hence \textbf{linear regression}).

\subsubsection{Example R-Code}
\begin{lstlisting}
library(datasets) # the dataset mtcars is located in this package
str(mtcars) # Compactly displays the internal structure of the object
summary(mtcars) # returns a six number summary of each variable in the data frame

mtcars1 <- data.frame(lMPG=log(mtcars$mpg), wCyl=sqrt(mtcars$cyl),
					  lDisp=log(mtcars$disp), lHP=log(mtcars$hp),
					  drat=mtcars$drat, lWT=log(mtcars$wt),
					  qsec=mtcars$qsec, VS=mtcars$vs, AM=mtcars$am,
					  wGear=sqrt(mtcars$gear), wCarb=sqrt(mtcars$carb))

mtc1.lm1 <- lm(lMPG ~ lDisp + lHP + lWT + drat + qsec + wCarb + wCyl
               + wGear + VS + AM, data=mtcars1)
\end{lstlisting}

Inspecting the \lstinline{summary(mtc1.lm1)} output:
\begin{lstlisting}
Call:
lm(formula = lMPG ~ lDisp + lHP + lWT + drat + qsec + wCarb + 
wCyl + wGear + VS + AM, data = mtcars1)

Residuals:
Min       1Q   Median       3Q      Max 
-0.16637 -0.06968  0.01446  0.05770  0.20108 

Coefficients:
Estimate Std. Error t value Pr(>|t|)  
(Intercept)  3.733511   1.325541   2.817   0.0103 *
lDisp       -0.167383   0.179541  -0.932   0.3618  
lHP         -0.159416   0.134980  -1.181   0.2508  
lWT         -0.377992   0.250297  -1.510   0.1459  
drat         0.004172   0.074864   0.056   0.9561  
qsec         0.014235   0.033289   0.428   0.6733  
wCarb       -0.149562   0.115652  -1.293   0.2100  
wCyl         0.188301   0.217927   0.864   0.3973  
wGear        0.449734   0.264221   1.702   0.1035  
VS          -0.040222   0.088789  -0.453   0.6552  
AM          -0.054940   0.098564  -0.557   0.5831  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.1134 on 21 degrees of freedom
Multiple R-squared:  0.9018,	Adjusted R-squared:  0.8551 
F-statistic: 19.29 on 10 and 21 DF,  p-value: 2.097e-08
\end{lstlisting}

According to the F test for significance of regression, at least one of the explanatory variables is significant because its P-value of 3.649e-07 is smaller than 0.05. However, according to the marginal test none of the coefficients is significant on the 5\% level (except the intercept). This happens if the explanatory variables itself are (highly) correlated. To find a better model, a criterion must be chosen to find the optimal model.

\subsubsection{Akaike's information criterion}
A criterion to find better models:
\begin{equation*}
AIC = -2(maximized \: Log-Likelihood) + 2 \cdot \#estimates\: parameters
\end{equation*}
\begin{equation*}
AIC = n\cdot log(\frac{1}{n}\sum_{i=1}^{n} R_i^2) + 2p + constant
\end{equation*}
-> The criterion needs to be minimized

\paragraph{Use the R function \lstinline{step} to auto apply AIC}
\mbox{}
\begin{lstlisting}
mtc1.vs <- step(mtc1.lm1,
                scope=list(lower=~ 1,
                           upper=~ lDisp + lHP + drat + lWT + qsec
                                 + wCarb + fCyl + fVS + fAM + fGear))
\end{lstlisting}

While the variable \lstinline{mtc1.vs} now contains the model with the lowest AIC, a summary of the optimization process can be collected using \lstinline{mtc1.vs$anova}.

\paragraph{Compare two models using \lstinline{anova}}
ToDo %TODO

\subsubsection{Local Regression (LOESS)}
In comparison to linear model, where a \textbf{line} is fitted on the data, the LOESS regression can be used to fit a \textbf{curve}.

The concept of a LOESS regression is the following:

\begin{enumerate}
	\tightlist
	% See: https://www.youtube.com/watch?v=Vf7oJ6z2LCc
	\item For each point
	\begin{enumerate}
		\tightlist
		\item Set current point as \textbf{focal point}.
		\item Fit a straight line (\lstinline{family="gaussian"}) or a parabola (\lstinline{family="symetric"}) for the window. Inside the window, the distance of the point to the focal point determines the weight of each point.
		\item Set point at intercept with fitted line (\textbf{pre-fitted point})
	\end{enumerate}
	\item Calculate the difference for each point to the \textbf{pre-fitted point}
	\item For each pre-fitted point
	\begin{enumerate}
		\item Fit a line again using, but this time using the wights based on the distance to the \textbf{pre-fitted point}.
	\end{enumerate}
\end{enumerate}

\subsubsection{Residuals}

While the error term $E_i$ is unobservable it can be estimated by analysing the residuals:

\begin{equation*}
\vec{R} = \vec{Y} - \bm{X}\vec{\hat{\beta}} = \vec{Y} - \bm{H}\vec{Y} = (\bm{I}-\bm{H})\vec{Y}
\end{equation*}
\begin{equation*}
\bm{H} = \bm{X}(\bm{X}^T\bm{X})^{-1}\bm{X}^T
\end{equation*}

\paragraph{Scaled residuals}
\begin{equation*}
\breve{R_i} = \frac{R_i}{\sqrt{1-H_{ii}}}, i=1,...,n
\end{equation*}

\paragraph{Standardised residuals}
\begin{equation*}
\tilde{R_i} = \frac{R_i}{\sqrt{\hat{\sigma}^2(1-H_{ii}})}, i=1,...,n
\end{equation*}

\subsubsection{Diagnostic plots}
\begin{description}
	\tightlist
	\item[Tukey-Anscombe plot] Also called residual plot. Residuals against the fitted values: Is used to detect nonconstant expectation of the errors.
	\item[scale-lcation plot] The square-root of the absolute values of the standardized residuals against the fitted values: Is used to detect nonconstant variance of the errors.
	\item[normal Q-Q plot] Ordered standardized residuals against their expected values under normality: Is used to detect non normality of the errors.
	\item[Residuals against time and/or space variables] Is used to detect stochastic dependency in the errors.
	\item[sensitivity plot] Standardized residuals against leverage overlaid by Cook’s distance contours: Is used to detect too influential observation in the data.
\end{description}

\paragraph{Cook's distance}

\begin{equation*}
d_i = \frac{1}{p}\tilde{R_i}^2\frac{H_{ii}}{1-H_{ii}}
\end{equation*}

\textbf{Guideline:} Practical experience has shown that observations with a Cook’s distance $d_i$ larger than 1 can be considered as too influential.

\paragraph{Boostrap simulations}
Is an informal way to check stochastic fluctuation:
\begin{enumerate}
	\tightlist
	\item Generate observations $y_i^*$ according to the model using new random errors.\\
	$y_i^*=\hat{y_i}+\hat{\sigma}\cdot e_i^*$.
	\item Calculate the regression fit with the explanatory variables given in the data set and the newly generated response values $y_i^*$. Add the new lines to the plots.
	\item Repeat n times (n=19 for 5\% significance level).
\end{enumerate}

\subsubsection{Multicollinearity}
Is the term if some predictors are a linear combination of others.\\
Detect collinearity:
\begin{itemize}
	\tightlist
	\item Examination of the correlation matrix of the predictors will reveal large pairwise collinearities.
	\item The Variance Inflation Factor (VIF).\\
	\begin{lstlisting}
mtc3.lm0 <- lm(mpg ~ ., data=mtcars3)
vif(mtc3.lm0)
	\end{lstlisting}
	\textbf{Guideline:} If VIF is larger than 5 to 10 for any variable then multicollinearity is of a dangerous size and needs to be addressed.
\end{itemize}

\subsubsection{Categorical predictors}
If a predictor variable is categorical (e.g. a tool type) and has two levels, an indicator variable is set up:

\begin{equation*}
x_i = \begin{cases}
0 & if \; tool\; type\; A \\
1 & if\; tool\; type\; B
\end{cases}
\end{equation*}

In case of more than two levels, multiple indicator variables must be introduced:

\begin{tabular}{lll}
	$x_i^{2,2}$ & $x_i^{2,3}$  &  \\ 
	0 & 0 & for observation of type A \\ 
	1 & 0 & for observation of type B \\ 
	0 & 1 & for observation of type C \\ 
\end{tabular}

\subsubsection{Prediction error sum of squares (PRESS)}
In predictive modelling, the model are assessed often by the leave-one-out method. In this procedure, one observation is selected and the regression model is fitted to the remaining n-1 observations. With this we find the \textbf{prediction error for observation i}.
\begin{equation*}
r_{(i)}=y_i-\hat{y_(i)}
\end{equation*}
The \textbf{PRESS} is then defined by the sum of squares of the n prediction errors:
\begin{equation*}
PRSS = \sum_{i=1}^{n}r^2_{(i)} = \sum_{i=1}^{n}(y_i-\hat{y_{(i)}})^2
\end{equation*}

\subsubsection{Cross validation}
Cross validation is a model evaluation technique that tells how well the results will generalise to an independent dataset from the same population.\\
Basic idea (as example a 5-fold cross validation):
\begin{enumerate}
	\tightlist
	\item Split the data into n folds (for example chunks of 20\%)
	\item Use one fold for testing and the other for training
	\item Repeat step 2 n times until every fold is once used for testing
	\item Compute mean squared prediction error (MSPE)
	\begin{equation*}
		MSPE_{CV}=\frac{1}{n}\sum_{i=1}^{n}(\hat{y}_i^{Test} - y_i)^2
	\end{equation*}
\end{enumerate}

\subsubsection{Model building process}

\begin{enumerate}
	\tightlist
	\item Clarify the task (purpose? goal?); are there already model approaches?
	\item Data Screening and Processing
	\item Model fitting; preferably with robust methods
	\item Residual and sensitivity analysis; does this dataset help solve the task? -> Go back to 3, 2, 1 depending on the result
	\item Variable selection; treat collinearities if necessary -> Go back to 3 depending on the result
	\item Checking model adequacy
	\begin{itemize}
		\tightlist
		\item Residual and sensitivity analysis with selected model(s)
		\item Check plausibility; match model(s) with subject matter expertise
		\item Consider out-of-sample validation (i.e., validation with unused data), especially if the model is to be used for prediction.
	\end{itemize}
	-> Go back to 1, 2, 3, ... depending on the result
	\item Reporting: It is key to be honest and openly report all data manipulations and decisions that were made.
\end{enumerate}
